---
layout: single
title: "Publications"
author_profile: true
sidebar:
  nav: main
author: Dayun Choi                    # authors.yml 파일에 존재하는 username 값
date: "2026-01-30 16:30"              # 최초 포스팅 날짜. 별도 정렬 순서가 없으면 이 값으로 정렬됨. 파일명에 기록되어있다면 생략 가능.
last_modified_at: "2026-01-31 16:00"  # 마지막 수정 날짜.
comments: false
---

(&dagger; denotes the corresponding author.)

---

## <span style="color:#4FC3F7;">Conference Proceedings</span>

- **D. Choi** and J.-W. Choi&dagger;, “SoundCompass: Navigating target sound extraction with effective directional clue integration in complex acoustic scenes,” in *Proc. International Conference on Acoustics, Speech and Signal Processing (ICASSP)*, IEEE, Barcelona, Spain, 2026, pp. 1–5. \[[Paper](https://arxiv.org/abs/2509.18561)\] \[[GitHub](https://github.com/ChoiShio/SoundCompass)\] \[[Demo](https://choishio.github.io/demo-SoundCompass/)\]
- **D. Choi** and J.-W. Choi&dagger;, “Multichannel-to-multichannel target sound extraction using direction and timestamp clues,” in *Proc. International Conference on Acoustics, Speech and Signal Processing (ICASSP)*, IEEE, Hyderabad, India, 2025, pp. 1–5. \[[Paper](https://doi.org/10.1109/ICASSP49660.2025.10890145)\] \[[GitHub](https://github.com/ChoiShio/M2M-TSE)\] \[[Demo](https://choishio.github.io/demo_M2M-TSE/)\]
- **D. Choi** and J.-W. Choi&dagger;, “Target sound extraction on multichannel reverberant mixture,” in *2024 Autumn Conference of the Acoustical Society of Korea (ASK)*, ASK, Busan, Korea, 2024, pp. 170–171.
- **D. Choi** and J.-W. Choi&dagger;, “Target sound extraction on reverberant mixture using sound-class label and timestamp information,” in *2024 Spring Conference of the Acoustical Society of Korea (ASK)*, ASK, Jeju, Korea, 2024, pp. 335–336.
- **D. Choi**, D. Lee, and J.-W. Choi&dagger;, “Low complexity dnn model for multichannel speech enhancement,” in *2023 Spring Conference of the Korean Society of Noise and Vibration Engineering (KSNVE)*, KSNVE, Samcheok, Korea, 2023, pp. 132–132.
- D. Lee, **D. Choi**, and J.-W. Choi&dagger;, “DeFT-AN RT: Real-time multichannel speech enhancement using dense frequency-time attentive network and non-overlapping synthesis window,” in *Proc. Interspeech*, ISCA, Dublin, Ireland, 2023, pp. 864–868. \[[Paper](https://doi.org/10.21437/Interspeech.2023-2437)\] \[[GitHub](https://github.com/donghoney0416/DeFT-AN-RT)\]

---

## <span style="color:#4FC3F7;">Journal Articles</span>

- Y. Shul, **D. Choi**, and J.-W. Choi&dagger;, “CST-former: Multidimensional attention-based transformer for sound event localization and detection in real scenes,” *arXiv preprint arXiv:2504.12870*, 2025. \[[Paper](https://arxiv.org/abs/2504.12870)\] \[[GitHub](https://github.com/yusunnny/CST-former)\]
- **D. Choi** and J.-W. Choi&dagger;, “Target sound extraction on reverberant mixture,” *The Journal of the Acoustical Society of America (JASA)*, vol. 154, no. 4_supplement, A270–A271, 2023. \[[Paper](https://doi.org/10.1121/10.0023494)\]

---