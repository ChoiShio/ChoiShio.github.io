---
layout: single
title: "Self-supervised Learning of Audio Representations from Audio-Visual Data using Spatial Alignment"
author: DaYun Choi
category: PaperReview
tags: audio visual self-supervised AVC AVSA classification detection
excerpt: # "First post"
date: "2022-06-21 20:30"
last_modified_at: "2022-06-21 20:30"
published: true
comments: true
---

논문 리뷰는 우리나라 말로 쓸 예정이다.  
영어로 다 쓰면 좋겠지만 그렇게 영어 실력이 좋지는 않아서 꽤 많은 시간이 걸릴 것 같기 때문이다.  
그래도 단어 자체는 영어가 많아서 비중은 꽤 많을 것으로 생각된다.

아무튼 이제 종강도 했으니 본격적으로 연구 주제를 정해봐야 하는데  
우선 교수님께서 주신 논문을 읽어보고 내 관심 분야와 어떤 접점이 있을지 살펴 보고자 한다.

기말고사 기간 전에 간단하게 읽고 나서 지금 다시 자세히 읽어보는 중에 작성하는 것이다.  
그래서 이 포스트를 계속 업데이트 하면서 내용을 늘려나갈 예정이다. 아니면 또 새 포스트를 추가할 수도 있고..  
혹시나 내용이 틀린 게 있으면 댓글을 달아주시거나 메일을 보내주시면 좋을 것 같아요 :)

---

본 논문은 제목만 봐도 꽤 많은 내용을 다루고 있다는 것을 알 수 있다.  
"Self-supervised Learning", "Audio Representations", "Audio-Visual Data", "Spatial Alignment"  
딥러닝을 한 번도 배워보지 않은 사람들은 이게 다 무엇일까 생각할 수도 있다.  
사실 나도 아직 audio 관련해서 딥러닝을 다루어 보지는 않았기에 생소한 주제이다.  
그래도 영상과 음성을 함께 다룰 수 있는 딥러닝 주제를 연구 주제로 삼고 싶어서 이 논문이 기반이 될 것 같다.

## Abstract
사람이 어떤 물체가 그 위치에 있다고 인식하기 위해서는 여러 감각을 활용해야 한다.  
본 논문에서는 그 감각을 시각(visual)과 청각(audio)으로 언급하고 있다.  
이 두 감각을 활용하여 그 물체에서 나오는 소리를 나타내기 위한 task를 수행하고자 한다.

크게 두 가지 방법이 있다.
- audio-visual correspondence (AVC)
- audio-visual spatial alignment (AVSA)

추후 더 자세히 설명하겠지만 간단히 말하면  
AVC는 물체에 대한 영상과 음성의 sync를 맞추는 것이라면,  
AVSA는 AVC에 더해 그 물체의 위치 정보까지 파악하는 방법이라 보면 된다.

이를 수행하기 위해서는 360도 video와 ambisonic audio가 필요하다.  
모든 방향의 영상과 음성 데이터가 필요하다고 생각하면 된다.  
먼저 "object detection"을 이용하여 물체가 그 영상에서 어느 위치에 있는지를 보고  
그 위치에 음성을 "beamforming" 하여 spatial alignment를 시도한다.  
이 두 감각을 특정 label 없이 동시에 학습시키는 self-supervised learning을 진행하는 것이 본 논문의 목표이다.

예를 들어 어떤 공연을 갔는데 눈 감고 들으면 누가 어디서 피아노를 치는지, 기타를 치는지, 노래를 부르는지 알 수 없다.  
분명 그 소리들은 잘 구별되는데 말이다. (물론 소음이 심하면 잘 구별이 안되기도 하고..)  
그런데 눈을 뜨는 순간 그 사실은 바로 확인되고 누구인지, 어디에 있는지 한 번에 파악할 수 있다.  
이렇게 multimodal 방식을 이용하여 딥러닝 모델의 성능을 더 높일 수 있기에 이와 관련된 연구가 계속해서 나오고 있다.
내가 생각하기에 "object-oriented"라는 단어가 이러한 task의 핵심 키워드가 아닐까 생각한다.

이제 본격적으로 본 논문의 내용을 작성하려고 하는데 아직 저도 생소한 개념이 많아서 일단 정리 차원에서 쓰는 것이니 우선 양해를 먼저 구합니다 ㅎㅎ

## Introduction
(TBA)

## Related work
(TBA)

## Learning from Spatial Audio Features
(TBA)

## Learning from Stereo Audio
(TBA)

## Experimental Results
(TBA)

## Conclusions and Future Work
(TBA)